# -*- coding: utf-8 -*-
"""5. EDA_ CARDIOTOCOGRAPHIC DATASET

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sYaGyA2paZbppUN91bl69FvRMUIZ9UlU
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# **CARDIOTOCOGRAPHIC DATASET**

---
# 01. Data Cleaning and Prepration
---

> ### Loading Dataset
"""

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Files/Cardiotocographic.csv')

data

data.shape

data.info()

"""
> ### Handling Missing Values
"""

data.isnull().sum()

data.dropna(inplace=True)

data.isnull().sum()

data.shape

data[data.duplicated()].shape

data[data.duplicated()]

data = data.drop_duplicates()

data['Tendency'].value_counts()

"""
### Checking outliers
"""

#sns.pairplot(data)

data.describe()

data = data[(data['NSP'] >= 0) & (data['NSP'] <= 3)]
data['NSP'] = data['NSP'].round()
data.shape

data['NSP'].value_counts()

"""---
# 02. Statistical Summary
---
"""

data_summa = data.describe()

data_summa

iqr = (data_summa.iloc[6]-data_summa.iloc[4])

iqr

iqr = pd.DataFrame(iqr)

iqr_t = iqr.T

iqr_t.index = ['IQR']
iqr_t

data_summa = pd.concat([data_summa,iqr_t])

data_summa

ll = data_summa.iloc[4] - 1.5*data_summa.iloc[8]
ll = pd.DataFrame(ll).T
ll.index = ['Lower Limit']
data_summa = pd.concat([data_summa,ll])

ul = data_summa.iloc[6] + 1.5*data_summa.iloc[8]
ul = pd.DataFrame(ul).T
ul.index=['Upper Limit']
data_summa = pd.concat([data_summa,ul])

data_summa

data.shape

"""* Total 2103 Rows of Fetal Heart Health Data
* From Central Tendencies we can infer that the data lies in very narrow range
  * 10 out of 14 Columns have mean value greater than 10
* Similarly we can see that most of the columns have a very narrow IQR.
    * 9 Columns have IQR smaller than 1
    * 4 Columns have IQR smaller than 30
* The baseline fetal heart rate (LB) tends to cluster around 133 beats per minute.
* The columns consistently has median close to zero.

---
# 03. Data Vizualization
---
"""

fig, axs=plt.subplots(2,4,figsize=(16,5))
plt.suptitle('histplot',size=20)
plt.tight_layout()
sns.histplot(data['LB'],ax=axs[0,0])
sns.histplot(data['ASTV'],ax=axs[0,1])
sns.histplot(data['MSTV'],ax=axs[0,2])
sns.histplot(data['ALTV'],ax=axs[1,0])
sns.histplot(data['MLTV'],ax=axs[1,1])
sns.histplot(data['Width'],ax=axs[1,2])
sns.histplot(data['AC'],ax=axs[0,3])
sns.histplot(data['FM'],ax=axs[1,3])

fig, axs=plt.subplots(2,3,figsize=(12,5))
plt.suptitle('histplot',size=20)
plt.tight_layout()
sns.histplot(data['UC'],ax=axs[0,0])
sns.histplot(data['DL'],ax=axs[0,1])
sns.histplot(data['DS'],ax=axs[0,2])
sns.histplot(data['DP'],ax=axs[1,0])
sns.histplot(data['Tendency'],ax=axs[1,1])
sns.histplot(data['NSP'],ax=axs[1,2])

plt.title('NSP',size=20)
plt.pie(data['NSP'].value_counts(),autopct='%.2f%%',labels=['1','2','3'])
plt.show()

data['NSP'].value_counts()

plt.colormaps

plt.figure(figsize=(16,8))
sns.heatmap(data.corr(),annot=True,cmap='hot')
plt.title('Correlation Heatmap',size=20)

c_mat = pd.DataFrame(data.corr().unstack().reset_index())
c_mat = c_mat.sort_values(by=0,ascending=False)
c_mat = c_mat.iloc[14:]
c_mat.columns = ['Feature1','Feature2','Correlation']

# TOP 10 Positive Correlations
c_mat.head(20)

#TOP 10 Negative Correlations
c_mat.tail(20)

data.corr().unstack().max()

plt.figure(figsize=(10,5))
sns.violinplot(data)



"""# 4. INSIGHTS
---
1. Positive Correlation :
  * No variables are ***strongly correlated (0.8 - 1)*** to each other.
  * MSTV and DL are also Strongly correlated to Width .
  * We can see that NSP and ASTV  are ***moderately correlated (0.60-0.79)**
  * Abnormal short-term variability (ALTV) is very ***weakly correlated(0.20 -0.39)***  with both NSP and ASTV.
2. Negative Correlations:
  * NSP is inversely related to UC .
  * ASTV tend to decrease as width increases.
  * ALTV shows a negative association with UC.
  * Mean long-term variability (MLTV) and mean short-term variability (MSTV) are negatively correlated with ASTV.
  * AC has an inverse relationship with both ALTV and NSP.
3. From the data we can infer that the categorical COlumn i.e NSP can be used as a target variable for Machine learning model.
4. Rest of the columns can be used as features.
"""

